#region Redis

https://habr.com/ru/companies/wunderfund/articles/685894/

Redis(Remote Dictionary Service) — опенсорсный сервер БД типа ключ-значение
Это сервер структур данных
Вместо того чтобы работать со строками БД, перебирать, сортировать, упорядочивать их,
информация изначально находится в структурах данных, которые нужны программисту

 Redis поддерживает типы:
 - Строка                       String
 - Битовый массив               Bitmap
 - Битовое поле                 Bitfield
 - Хеш-таблица                  Hash
 - Список                       List
 - Множество                    Set
 - Упорядоченное множество      Sorted set
 - Геопространственные данные   Geospatial
 - Структура HyperLogLog        HyperLogLog
 - Поток                        Stream

 Redis — это БД, размещаемая в памяти, которая используется преимущественно в роли кеша,
 находящегося перед другой, настоящей БД, вроде MySQL или PostgreSQL

 Кеш, основанный на Redis, помогает улучшить производительность и смягчает нагрузку центральной БД,
 связанную с обработкой:
 - данных, которые редко меняются, к которым часто обращаются
 - не критически важных данных, которые часто меняются

 Примеры таких данных:
 - сессионные кеши или кеши данных
 - списки лидеров и отчёты, включающие данные, агрегированные из разных источников

Традиционный подход к использованию Redis:
1. Клиент обращается к приложению, оно получает необходимые данные
2. Приложение обращается к кешу Redis, представленному главной БД
- Если данные в кеше есть - выполняется обычный возврат данных
- Если данных нет - система обращается к основной БД MySQL
Данные из нее загружаются в кеш, после чего ими сможет воспользоваться приложение

 Redis гарантирует сохранность данных,
 что позволяет использовать эту СУБД в роли основной БД
 Чтение данных из памяти и работа с данными, находящимися в памяти, гораздо быстрее операций,
 выполняемых традиционными СУБД с HDD или SSD

 ######################## АРХИТЕКТУРА REDIS ########################

Хабр (https://habr.com/ru/companies/wunderfund/articles/685894/)

 Варианты развёртывания этого хранилища:
 - Единственный экземпляр Redis
 - Redis HA
 - Redis Sentinel
 - Redis Cluster

 // Единственный экземпляр Redis:

 Самый простой вариант развёртывания Redis

 Если используемый в проекте экземпляр Redis даст сбой или окажется недоступным,
 обращения клиентов к Redis окажутся неудачными

 Если дать экземпляру Redis достаточно памяти и серверных ресурсов - он может стать мощной сущностью
 Такой подход используется для кеширования и позволяет получить серьёзный рост производительности

 При наличии достаточных серверных ресурсов развернуть подобный сервис можно на той же машине,
 на которой работает основное приложение

 Запросы, поступающие к БД Redis, обрабатываются путём работы с данными, хранящимися в памяти
 Если используемый экземпляр Redis предусматривает применение постоянного хранения данных,
 в системе будет форк процесса
 Он использует RDB (Redis Database) для организации постоянного хранения снепшотов (снимков) данных
 Это компактное представление данных Redis на определённый момент времени
 Вместо RDB могут использоваться файлы, предназначенные только для добавления данных (Append-Only File, AOF).

 Эти два механизма позволяют Redis:
 - иметь долговременное хранилище данных
 - поддерживать различные стратегии репликации
 - помогают реализовывать на базе Redis более сложные топологии

 Если сервер Redis не настроен на постоянное хранение данных - при перезагрузке или сбое данные теряются
 Если постоянное хранение включено - при перезагрузке 
 осуществляется загрузка в память данных из снепшота RDB или из AOF

 // Redis HA:

 Эта конфигурация Redis характеризуется большей распределённостью
 В состав системы входят
 - главная база данных (Main) - ведущий узел
 - второстепенная база данных (Secondary) — подчинённый узел
 Состояние узлов синхронизируется посредством репликации

 По мере того, как данные записываются в ведущем экземпляре Redis,
 копии соответствующих команд отправляются в выходной буфер для подчинённых узлов,
 что обеспечивает репликацию
 В состав подчинённых узлов может входить один или большее количество экземпляров Redis
 Эти экземпляры способны помочь в масштабировании операций чтения данных или обеспечить отказоустойчивость системы при потере связи с ведущим узлом

 // Репликация данных в Redis:

 Каждый ведущий узел Redis имеет ID и смещение репликации
 Эти два показателя важны для того, чтобы выяснить, когда подчинённый узел может продолжать репликацию
 или чтобы определить, что необходимо выполнить полную синхронизацию данных

 Смещение инкрементируется при выполнении любого действия, которое происходит в ведущем узле Redis

 Replication ID, offset

 Когда подчинённый узел Redis отстаёт лишь на несколько шагов смещения от ведущего узла,
 он получает оставшиеся необработанными команды от ведущего узла, эти команды применяются к данным,
 так происходит до момента синхронизации узлов

 Если два экземпляра не могут договориться об ID репликации,
 или ведущий узел не знает о смещении, подчинённый узел запрашивает полную синхронизацию данных

 Сюда входит создание ведущим узлом нового снепшота RDB и отправка его подчинённому узлу
 В процессе передачи этих данных ведущий узел буферизует промежуточные обновления данных,
 произошедшие между моментом создания снепшота и текущим моментом

 Эти обновления будут отправлены подчинённому узлу после того, как он синхронизируется со снепшотом
 После завершения этого процесса репликация продолжится в обычном режиме

 Если у разных экземпляров Redis одинаковые ID и смещение, то они хранят одни и те же данные
 Redis использует ID репликации, потому что когда уровень экземпляра Redis повышается до ведущего узла,
 или если экземпляр сразу запускается как ведущий, ему назначается новый ID репликации
 Он используется для выяснения, какой экземпляр Redis был до этого ведущим - из какого экземпляра раньше копировал данные узел, уровень которого был только что повышен

 Это позволяет выполнение частичной синхронизации с другими подчинёнными узлами,
 так как новый ведущий узел помнит свой старый ID репликации

 Например, два экземпляра Redis, ведущий и подчинённый, имеют один и тот же ID репликации,
 а их смещения отличаются на несколько сотен команд
 Если на отстающем экземпляре воспроизвести соответствующие команды, в распоряжении обоих экземпляров будет идентичный набор данных
 Предположим, что ID репликации экземпляров различаются и нам неизвестен предыдущий ID
 (у экземпляров нет общего предка) узла, уровень которого недавно понижен до подчинённого
 (он подключён к ведущему узлу)
 Тогда нужно выполнить ресурсозатратную операцию полной синхронизации данных

 А если предыдущий ID репликации известен — можем подумать о том, как синхронизировать данные двух узлов
 Так как известен общий предок узлов, это значит, что они хранят общие данные, а значит,
 воспользовавшись смещением, можем провести частичную синхронизацию данных

 // Redis Sentinel:

 Redis Sentinel — это сервис, обеспечивающий создание распределённых систем
 В основе Sentinel лежит кластер Sentinel-процессов, работающих совместно
 Они координируют состояние системы, реализуя конфигурацию высокой доступности Redis
 Sentinel — это сервис, защищающий хранилище Redis от сбоев и не имеет единой точки отказа

 Сервис Sentinel решает несколько задач
 - обеспечивает работоспособность и доступность текущих ведущих и подчинённых узлов
   Благодаря этому текущий Sentinel-процесс (вместе с другими подобными процессами) может отреагировать на ситуацию, когда теряется связь с ведущими и/или подчинёнными узлами
 - играет роль в обнаружении сервисов. Похожим образом в других системах работают Zookeeper и Consul
   Когда новый клиент пытается что-то записать в хранилище Redis, Sentinel сообщит клиенту о том, какой экземпляр Redis в этот момент является ведущим

 Узлы Sentinel постоянно мониторят доступность экземпляров Redis и отправляют сведения о них клиентам, что позволяет клиентам предпринимать действия в случае сбоя

 Вот какие функции выполняют узлы Sentinel:
 - Мониторинг - обеспечение того, что ведущие и подчинённые узлы работают так, как ожидается
 - Отправка уведомлений администраторам о происшествиях в экземплярах Redis
 - Управление восстановлением системы после отказа, если ведущий экземпляр Redis недоступен и достаточное количество узлов согласно с тем, что это так
 - Управление конфигурацией - позволяет обнаруживать текущий ведущий экземпляр Redis

 Кворум — это минимальное число голосов, которое нужно получить распределённой системе,
 чтобы ей было позволено выполнять определённые операции, наподобие восстановления после сбоя
 Это число поддаётся настройке, но должно отражать количество узлов в рассматриваемой распределённой системе
 Размеры большинства распределённых систем равняются трём или пяти узлам, в них кворум равен двум или трём - нечётные количества узлов предпочтительны для разрешения неоднозначностей

 Redis Sentinel можно развернуть несколькими способами
 Рекомендуется запускать узел Sentinel вместе с каждым из серверов приложения, если возможно
 Это позволит не обращать внимания на различия, связанные с сетевыми подключениями узлов Sentinel и клиентов, которые используют Redis

 Sentinel можно запустить и на тех же машинах, на которых работают экземпляры Redis,
 или в виде независимых узлов, но это усложняет ситуацию
 Рекомендую применять минимум три узла с кворумом из двух

 Таблица с описанием количества серверов в кластере, сведениях о кворуме и количестве допустимых отказов

 Количество серверов | Кворум | Количество допустимых отказов
  1     1    0
  2     2    0
  3     2    1
  4     3    1
  5     3    2
  6     4    2
  7     4    3

 1. Что если узлы Sentinel выйдут из состава кворума?
 2. Что если сеть разделится и старый ведущий экземпляр Redis окажется в меньшей группе узлов Sentinel? Что произойдёт с данными, записанными в этот экземпляр Redis? (они после полного восстановления системы будут утеряны)
 3. Что если сетевые топологии узлов Sentinel и клиентских узлов (узлов приложения) окажутся несогласованными?

 Нет гарантий устойчивости системы, особенно учитывая,
 что операции сохранения данных на диск выполняются асинхронно

 Есть проблема, связанная с тем, когда клиенты узнают о появлении новых ведущих узлов
 Сколько команд записи данных уйдут в никуда, будучи отправленными в ситуации, когда новый ведущий узел неизвестен?
 Разработчики Redis рекомендуют запрашивать сведения о новом ведущем узле при установлении новых соединений
 Это, что зависит от конфигурации системы, может приводить к серьёзным потерям данных

 Можно уменьшить потери данных если принудить ведущий экземпляр Redis к репликации операций записи на минимум один подчинённый экземпляр. Репликация в Redis выполняется асинхронно, и у нее есть недостатки. Поэтому понадобится независимо отслеживать подтверждения получения данных, а если не удастся получить подтверждение от хотя бы одного подчинённого узла - главный узел должен прекратить принимать запросы на запись данных.

 // Redis Cluster:

  Клиенты выполняют операции чтения/записи, взаимодействуя с ведущими узлами Redis
  Между ведущими и подчинёнными выполняется репликация данных
  Другие клиенты, обращаясь к подчинённым узлам, выполняют операции чтения данных
  Для определения общего состояния кластера используется протокол Gossip

 Как быть, если не получится хранить необходимые данные в памяти на одной машине?
 Redis Cluster позволяет горизонтально масштабировать хранилища Redis
 По мере роста системы её владелец может выбрать вариант действий:
 - Меньше работать
 - Повышать мощность отдельных компьютеров
 - Распределять нагрузку на большее количество небольших компьютеров

 Два последние пункта известны как вертикальное и горизонтальное масштабирование
 - При вертикальном для ускорения работы используют более продвинутые компьютеры, надеясь, что возросшая вычислительная мощность позволит справляться с растущей нагрузкой. Но это работает на первых порах, в итоге мы столкнемся с ограничениями аппаратного обеспечения
 - Горизонтальное масштабирование -это распределение нагрузки по множеству небольших машин, ответственных за решение небольших подзадач одной большой задачи

 Распределение хранимых данных по множеству машин называют шардингом
 Каждый экземпляр Redis, входящий в состав кластера, считается хранилищем шарда, или фрагмента всех данных

 Такой подход приводит к новой проблеме
 Если отправить в кластер данные — как узнать, какой экземпляр Redis (шард) хранит их
 Redis Cluster использует алгоритмический шардинг
 Чтобы найти шард для заданного ключа, мы хешируем ключ, а результат делим по модулю на количество шардов
 Затем, используя детерминистическую хеш-функцию (благодаря этому конкретный ключ всегда будет соответствовать одному и тому же шарду), мы, когда нужно будет прочитать соответствующие данные, сможем узнать о том, где они хранятся

 Что произойдёт, если через некоторое время в систему будет добавлен новый шард?
 Произойдёт то, что называют решардингом

 Исходя из предположения, что ключ foo был назначен шарду 0, он после решардинга может быть назначен шарду 5

 Но перемещение данных ради того, чтобы их размещение соответствовало бы новой конфигурации шардов, окажется медленной задачей, если мы хотим, чтобы операции по увеличению хранилища выполнялись бы быстро
 Такое перемещение данных так-же окажет негативное влияние на доступность Redis Cluster

 В рамках Redis Cluster создан механизм, направленный на решение этой проблемы - хеш-слоты, в которые отправляют данные
 Имеется около 16 тысяч таких слотов -это даёт способ распределения данных по кластеру, а при добавлении новых шардов нужно просто переместить в системе хеш-слоты

 Поступая так, нам нужно лишь перемещать хеш-слоты из шарда в шард и упростить процесс добавления новых ведущих экземпляров Redis в кластер

 Сделать это можно без простоев системы и с минимальным воздействием на её производительность
 Рассмотрим пример.
 Узел M1 содержит хеш-слоты с 0 по 8191
 Узел M2 содержит хеш-слоты с 8192 по 16383
 Назначая хеш-слот ключу foo, вычисляем детерминистический хеш от ключа (foo) и делим по модулю на количество хеш-слотов (16383)
 В результате данные, соответствующие этому ключу, попадают на узел M2
 Предположим, мы добавляем в систему новый узел — M3
 Новое соответствие узлов и хеш-слотов будет таким:
 Узел M1 содержит хеш-слоты с 0 по 5460
 Узел M2 содержит хеш-слоты с 5461 по 10922
 Узел M3 содержит хеш-слоты с 10923 по 16383
 Все ключи, которые попали в хеш-слоты узла M1, теперь принадлежащие узлу M2, понадобилось бы перенести
 Но соответствие отдельных ключей и хеш-слотов сохраняется, так как ключи уже распределены по хеш-слотам
 Так данный механизм решает проблему решардинга при использовании алгоритмического шардинга

 // Протокол Gossip:

 Redis Cluster использует протокол Gossip для определения общего состояния кластера
 На вышеприведённой иллюстрации имеется 3 ведущих (M) узла и 3 подчинённых (S) узла
 Все они постоянно обмениваются друг с другом информацией, чтобы знать, какие шарды доступны и готовы обрабатывать запросы

 Если достаточное количество шардов согласно с тем, что узел M1 не отвечает на запросы, они могут решить повысить S1 — подчинённый узел узла M1, до уровня ведущего узла, чтобы поддержать кластер в работоспособном состоянии

 Количество узлов, необходимое для запуска подобной процедуры, поддаётся настройке
 Очень важно правильно выполнить подобную настройку
 Если сделать что-то не так, кластер может оказаться разделённым на части в том случае, если он не сможет разрешить неоднозначную ситуацию, когда «за» и «против» голосует одинаковое количество систем
 Этот феномен называют split brain (разделение вычислительных мощностей)
 Поэтому важно, чтобы в кластере было нечётное количество ведущих узлов, у каждого из которых имеется два подчинённых узла

 // Модели постоянного хранения данных в Redis:

 Если в Redis планируется размещать данные в расчёте на их надёжное постоянное хранение, важно понимать, как это организовано в Redis
 Существюет ситуации, когда потеря данных в Redis — не такая уж и катастрофа
 Например — использование Redis в роли кеша, или в ситуациях, когда в Redis хранятся данные некоей аналитической системы реального времени
 В других случаях разработчикам нужны некие гарантии относительно постоянного хранения данных и возможности их восстановления
 Redis — быстрое хранилище, а все гарантии относительно целостности данных второстепенны в сравнении со скоростью

 Модели постоянного хранения данных в Redis
 Данные из памяти копируются либо в RDB, в виде снепшотов, либо в AOF
 Если экземпляр Redis отказал, но данные этого экземпляра были помещены в постоянное хранилище - эти данные загружаются в новый экземпляр Redis

 // Постоянное хранение данных не используется
 При желании постоянное хранение данных можно отключить
 Тогда Redis работает быстрее всего, но не гарантируется надёжное хранение данных

 // RDB-файлы
 Постоянное хранение данных в файлах RDB подразумевает создание снепшотов,
 содержащих данные, актуальные на определённые моменты времени
 Снепшоты создаются с заданными временными интервалами

 Минус в том, поступившие в хранилище между моментами создания снепшотов данные при сбое Redis будут утеряны
 Кроме того, этот механизм хранения данных полагается на создание форка главного процесса
 При работе с большими наборами данных это может привести к задержкам в обработке запросов
 Но RDB-файлы загружаются в память гораздо быстрее AOF

 // AOF
 Механизм постоянного хранения данных, основанный на AOF,
 осуществляет журналирование каждой операции записи, запрос на выполнение которой получает сервер
 Эти операции будут воспроизведены при запуске сервера, что приведёт к воссозданию исходного набора данных

 Такой подход к постоянному хранению данных гораздо надёжнее RDB
 Речь идёт не о снимках состояния хранилища, а о файлах, рассчитанных только на присоединение к ним данных
 Когда происходят операции, их буферизуют в журнале, но они не оказываются сразу после этого размещёнными в постоянном хранилище
 В журнале содержатся реальные команды, которые, если нужно восстановить данные, запускают в том порядке, в котором они выполнялись

 Затем журнал сбрасывают на диск с помощью fsync
 После этого данные оказываются в постоянном хранилище
 Минус этого подхода, что такой формат хранения данных требует больше места на диске, чем RDB-файлы

 Вызов fsync() сбрасывает все модифицированные данные из памяти, имеющие отношение к файлу,
 представленному файловым дескриптором fd, на дисковое устройство
 В результате вся изменённая информация может быть восстановлена даже после серьёзного сбоя

 Изменения, которые вносят в открытый файл, сначала попадают в кеш, а вызов fsync() гарантирует,
 что они будут физически сохранены на диск, то есть — позже их можно будет с диска прочитать

 Можно скомбинировать AOF и RDB в одном и том же экземпляре Redis,
 если надёжность хранения данных в обмен на некоторое снижение скорости вас устраивает
 При этом, если система будет перезагружена, для восстановления данных Redis будет использовать AOF,
 так как в этом хранилище находится более полная версия данных

 // Создание форков процессов Redis
 Теперь, когда мы разобрались с механизмами организации постоянного хранения данных в Redis, поговорим о том, как это делается в однопоточном приложении наподобие Redis.

 Снепшот содержит данные, актуальные на определённый момент времени
 После создания форка данные копируются на диск

 Самое приятное в Redis — то, как тут используется создание форков и копирование при записи
 для реализации высокопроизводительного копирования данных в постоянное хранилище

 Форк — это когда операционная система по команде, вызванной неким процессом, создаёт новый процесс, копируя родительский процесс
 В результате в нашем распоряжении оказывается новый ID процесса и ещё некоторые полезные сведения
 При этом только что созданный форк процесса (процесс-потомок) может взаимодействовать с процессом-родителем

 Redis — это процесс, которому выделено огромное количество памяти
 Как скопировать такой процесс и не столкнуться с нехваткой памяти?

 Когда создают форк процесса — процесс-родитель и процесс-потомок используют память совместно
 Redis начинает процесс создания снепшота в процессе-потомке
 Это возможно благодаря копированию при записи, когда
 во время создания форка память не выделяется, используются ссылки на уже выделенную память
 Если во время сброса данных дочерним процессом на диск ничего в памяти не менялось, новая память выделяться не будет

 Если изменения были ядро ОС отслеживает ссылки на каждую страницу памяти
 Если на некую страницу имеется больше одной ссылки — изменения записываются в новые страницы
 Процесс-потомок ничего не знает об изменениях, в его распоряжении имеется стабильный снимок памяти
 В результате для создания форка процесса используется лишь небольшой объём памяти
 Мы можем быстро и эффективно создавать снепшоты, отражающие состояние хранилища на некий момент времени,
 размеры которых могут достигать многих гигабайтов

 https://metanit.com/sharp/aspnet6/17.1.php
 
 Кэширование - сохранение данных в специальном месте для более быстрого доступа
 Значительно повышает производительность приложения ASP.NET,
 существенно уменьшая количество обращений к источникам данных, например, БД

 Когда надо кэшировать данные:
 - Когда данные являются внешними по отношению к приложению, например, приходят из БД
 - Когда данные не часто обновляются
 - Когда данные часто используются в приложении

 При этом речь не идет о кэшировании всей таблицы БД или нескольких таблиц
 Это может быть часть таблицы

 Распространенные причины кэширования:
 - Кэширование результатов запросов к БД
 - Кэширование, когда приложение располагается в такой сетевой конфигурации,
   в которой некоторые аспекты сети замедляют работу приложения
   Например, приложение располагается за файерволом, и валидация запросов занимает время
   В этом случае кэш обычно располагается на другом хосте, где подобная задержка минимальна
 - Кэширование для управления состоянием - кэш может представлять состояние,
   которое могут использовать различные экземпляры приложений или части одного приложения

 Стратегии кэширования:
 - Прекэширование
    Путем анализа разработчик определяет наиболее часто запрашиваемые данные
   Они кэшируются при старте приложения, затем после запуска берем данные из кэша вместо запрашивания из внешнего источника
   Минус подобного подхода - необходимость синхронизации с внешним источником данных в случае их обновления
 - Кэширование по запросу
   Когда данные необходимы - приложение сначала обращается в кэш
   Если там найдены соответствующие данные - они используются
   Если данные в кэше отстуствуют - приложение извлекает их из БД и кэшируют для последующих запросов
   Минус - необходимость делать запрос к БД, который снижает производительность приложения
   
 // MemoryCache
 Самым простым способом кэширования в ASP.NET Core является использование
 "Microsoft.Extensions.Caching.Memory.IMemoryCache", который позволяет сохранять данные в кэше на сервере 
 
 Применяя методы интефейса IMemoryCache, мы можем управлять кэшем:
 - bool TryGetValue(object key, out object value)
   Пытаемся получить элемент по ключу key
   При успешном получении параметр value заполняется полученным элементом, а метод возвращает true
 - object Get(object key)
   Дополнительный метод расширения, который получает по ключу key элемент и возвращает его
 - void Remove(object key)
   Удаляет из кэша элемент по ключу key
 - object Set(object key, object value, MemoryCacheEntryOptions options)
   Добавляет в кэш элемент с ключом key и значением value, применяя опции кэширования MemoryCacheEntryOptions
 - ICacheEntry CreateEntry(object key)
   Добавляет в кэш или перезаписывает запись с ключом key, возвращает новую запись

 ASP.NET Core предоставляет встроенную реализацию интерфейса "IMemoryCache" - класс "MemoryCache"

 Допустим, надо кэшировать информацию о пользователе,
 которая может не изменяться в течение более долгого периода времени

 Для простоты и демонстрации в качестве БД используем SQLite и Entity Framework

 https://metanit.com/sharp/aspnet6/17.1.php
 
 Кэширование - сохранение данных в специальном месте для более быстрого доступа
 Значительно повышает производительность приложения ASP.NET,
 существенно уменьшая количество обращений к источникам данных, например, БД

 Когда надо кэшировать данные:
 - Когда данные являются внешними по отношению к приложению, например, приходят из БД
 - Когда данные не часто обновляются
 - Когда данные часто используются в приложении

 При этом речь не идет о кэшировании всей таблицы БД или нескольких таблиц
 Это может быть часть таблицы

 Распространенные причины кэширования:
 - Кэширование результатов запросов к БД
 - Кэширование, когда приложение располагается в такой сетевой конфигурации,
   в которой некоторые аспекты сети замедляют работу приложения
   Например, приложение располагается за файерволом, и валидация запросов занимает время
   В этом случае кэш обычно располагается на другом хосте, где подобная задержка минимальна
 - Кэширование для управления состоянием - кэш может представлять состояние,
   которое могут использовать различные экземпляры приложений или части одного приложения

 Стратегии кэширования:
 - Прекэширование
    Путем анализа разработчик определяет наиболее часто запрашиваемые данные
   Они кэшируются при старте приложения, затем после запуска берем данные из кэша вместо запрашивания из внешнего источника
   Минус подобного подхода - необходимость синхронизации с внешним источником данных в случае их обновления
 - Кэширование по запросу
   Когда данные необходимы - приложение сначала обращается в кэш
   Если там найдены соответствующие данные - они используются
   Если данные в кэше отстуствуют - приложение извлекает их из БД и кэшируют для последующих запросов
   Минус - необходимость делать запрос к БД, который снижает производительность приложения
   
 // MemoryCache
 Самым простым способом кэширования в ASP.NET Core является использование
 "Microsoft.Extensions.Caching.Memory.IMemoryCache", который позволяет сохранять данные в кэше на сервере 
 
 Применяя методы интефейса IMemoryCache, мы можем управлять кэшем:
 - bool TryGetValue(object key, out object value)
   Пытаемся получить элемент по ключу key
   При успешном получении параметр value заполняется полученным элементом, а метод возвращает true
 - object Get(object key)
   Дополнительный метод расширения, который получает по ключу key элемент и возвращает его
 - void Remove(object key)
   Удаляет из кэша элемент по ключу key
 - object Set(object key, object value, MemoryCacheEntryOptions options)
   Добавляет в кэш элемент с ключом key и значением value, применяя опции кэширования MemoryCacheEntryOptions
 - ICacheEntry CreateEntry(object key)
   Добавляет в кэш или перезаписывает запись с ключом key, возвращает новую запись

 ASP.NET Core предоставляет встроенную реализацию интерфейса "IMemoryCache" - класс "MemoryCache"

 Допустим, надо кэшировать информацию о пользователе,
 которая может не изменяться в течение более долгого периода времени

 Для простоты и демонстрации в качестве БД используем SQLite и Entity Framework

 Далее определим в файле Program.cs следующий код приложения:
 - Класс User описывает используемые данные, его объекты будут храниться в БД SQLite
 - Для взаимодействия с БД применяется класс контекста данных ApplicationContext
 - Для тестирования в методе OnModelCreating() инициализируем БД тремя объектами
 - Для взаимодействия с контекстом данных и кэшем определен класс UserService
   Данный сервис через внедрение зависимостей будет получать контекст данных и использовать его
   для взаимодействия с БД
   Кроме того, здесь реализуем логику кэширования
   Через механизм внедрения зависимостей в конструкторе можем получить объект кэша IMemoryCache
 - В методе GetUser() сервис UserService получает объект User по id
   При получении объекта вначале пытаемся найти этот объект в кэше
   Здесь ключами элементов в кэше являются значения id, а значения элементов - объекты User
   Если ключ в кэше был найден - в объект user передается извлекаемое из кэша значение,
   а метод TryGetValue() возвращает true
 - Если в кэше не оказалось объекта - извлекаем его из БД и добавляем в кэш
 - Для добавления в кэш в метод Set() передаем ключ объекта - его Id,
   затем передаем само кэшируемое значение - извлеченный из БД объект User
   В конце для установки времени кэширования применяется метод SetAbsoluteExpiration
   объекта MemoryCacheEntryOptions, который в данном случае таже устанавливает 5 минут
 
 https://metanit.com/sharp/aspnet6/17.1.php
 
 // Регистрация IMemoryCache
 Чтобы получить сервис IMemoryCache в приложении - его необходимо добавить в коллекцию сервисов
 "builder.Services.AddMemoryCache();"
 
 Этот сервис устанавливает зависимость для IMemoryCache, создавая объект синглтон:
 "builder.Services.TryAdd(ServiceDescriptor.Singleton<IMemoryCache, MemoryCache>());"


 Для тестирования определим конечную точку, где клиент передает id через параметр маршрута,
 и сервис UserService по этому id пытается найти в базе данных и кэше нужный объект User:

 app.MapGet("/user/{id}", async (int id, UserService userService) =>
 {
     User? user = await userService.GetUser(id);
     if (user is not null) return $"User {user.Name}  Id={user.Id}  Age={user.Age}";
     return "User not found";
 });

Запустим приложение и обратимся по адресу
 https://localhost:xxxx/user/1
 для получения объекта User с id=1
 При первом обращении к приложению данные будут извлекаться из БД и сохраняться в кэш
 При последующих обращениях в пределах времени кэширования (в данном случае 5 минут) данные будут извлекаться из кэша

 // MemoryCacheEntryOptions
 Для установки параметров кэширования в метод Set() в качестве третьего параметра передается объект MemoryCacheEntryOptions, который устанавливает настройки кэширования объекта с помощью свойств:
 - "AbsoluteExpiration" возвращает или задает абсолютную дату окончания кэширования
 - "AbsoluteExpirationRelativeToNow" возвращает или задает абсолютную дату окончания кэширования относительно текущего момента
 - "ExpirationTokens" возвращает токены в виде объектов IChangeToken, которые приводят к истечению срока действия записи в кэше
 - "PostEvictionCallbacks" возвращает или задает колбеки, которые вызываются после удаления записи из кэша
 - "Priority" возвращает или задает приоритет сохранения записи в кэше во время очистки,
   активируемой при нехватке памяти
   Представляет одно из значений перечисления CacheItemPriority
   Значение по умолчанию — Normal
   Другие значения - High, Low и NeverRemove
 - "Size" возвращает или задает размер значения записи в кэше
 - "SlidingExpiration" возвращает или задает время, в течение которого запись кэша может быть неактивной (то есть к ней нет обращений), прежде чем она будет удалена
 Это значение не увеличивает время существования записи сверх абсолютного срока действия.
 
 Применим ряд этих свойств, для этого изменим в классе UserService следующим образом
 https://metanit.com/sharp/aspnet6/17.1.php
 
 Коллбек вызывается не сразу после окончания срока кэширования записи,
 а при первом обращении к кэшу после завершении кэширования
